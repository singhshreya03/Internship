{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aef8698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Obtaining dependency information for selenium from https://files.pythonhosted.org/packages/97/e3/fd7272d6d2c49fd49a79a603cb28c8b5a71f8911861b4a0409b3c006a241/selenium-4.17.2-py3-none-any.whl.metadata\n",
      "  Downloading selenium-4.17.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in ./anaconda3/lib/python3.11/site-packages (from selenium) (1.26.16)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Obtaining dependency information for trio~=0.17 from https://files.pythonhosted.org/packages/14/fb/9299cf74953f473a15accfdbe2c15218e766bae8c796f2567c83bae03e98/trio-0.24.0-py3-none-any.whl.metadata\n",
      "  Downloading trio-0.24.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Obtaining dependency information for trio-websocket~=0.9 from https://files.pythonhosted.org/packages/48/be/a9ae5f50cad5b6f85bd2574c2c923730098530096e170c1ce7452394d7aa/trio_websocket-0.11.1-py3-none-any.whl.metadata\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in ./anaconda3/lib/python3.11/site-packages (from selenium) (2023.11.17)\n",
      "Collecting typing_extensions>=4.9.0 (from selenium)\n",
      "  Obtaining dependency information for typing_extensions>=4.9.0 from https://files.pythonhosted.org/packages/b7/f4/6a90020cd2d93349b442bfcb657d0dc91eee65491600b2cb1d388bc98e6b/typing_extensions-4.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: attrs>=20.1.0 in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for outcome from https://files.pythonhosted.org/packages/55/8b/5ab7257531a5d830fc8000c476e63c935488d74609b50f9384a643ec0a62/outcome-1.3.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in ./anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m965.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading selenium-4.17.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m780.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.24.0-py3-none-any.whl (460 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.2/460.2 kB\u001b[0m \u001b[31m214.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: typing_extensions, sniffio, outcome, h11, wsproto, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.17.2 sniffio-1.3.0 trio-0.24.0 trio-websocket-0.11.1 typing_extensions-4.9.0 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78741675",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_element_by_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome() \u001b[38;5;66;03m#launch crome browser\u001b[39;00m\n\u001b[1;32m     13\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.shine.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#open shine.com\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m job_title_input \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element_by_id(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqsb-keyskill-sugg\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#find job title, location and put search area\u001b[39;00m\n\u001b[1;32m     16\u001b[0m job_title_input\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata Analyst\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m location_input \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element_by_id(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqsb-location-sugg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_element_by_id'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome() #launch crome browser\n",
    "\n",
    "\n",
    "driver.get(\"https://www.shine.com/\") #open shine.com\n",
    "\n",
    "job_title_input = driver.find_element_by_id(\"qsb-keyskill-sugg\") #find job title, location and put search area\n",
    "job_title_input.send_keys(\"data Analyst\")\n",
    "\n",
    "location_input = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "location_input.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "search_button = driver.find_element_by_class_name(\"btn-search\") #for search button\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "time.sleep(2) #page loading\n",
    "\n",
    "jobs = driver.find_elements_by_xpath(\"//li[@class='s-l-i']\")[:10] #scrape data \n",
    "\n",
    "job_data = []\n",
    "\n",
    "for job in jobs:\n",
    "    \n",
    "    job_title = job.find_element_by_class_name(\"job_title\").text.strip()\n",
    "    company_name = job.find_element_by_class_name(\"company_name\").text.strip()\n",
    "    job_location = job.find_element_by_class_name(\"loc\").text.strip()\n",
    "    experience_required = job.find_element_by_class_name(\"exp\").text.strip()\n",
    "    \n",
    "    job_data.append({\n",
    "        \n",
    "        \"Job Title\": job_title,\n",
    "        \"Company Name\": company_name,\n",
    "        \"Job Location\": job_location,\n",
    "        \"Experience Required\": experience_required\n",
    "    })\n",
    "\n",
    "\n",
    "driver.quit()  #browser clean\n",
    "\n",
    "\n",
    "df = pd.DataFrame(job_data)  #create dataframe \n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ee6afe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_shine_jobs(job_title, location, num_jobs=10):\n",
    "    url = f\"https://www.shine.com/job-search/{job_title}-jobs-in-{location}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        jobs = soup.find_all(\"li\", class_=\"s-l-i\")[:num_jobs]\n",
    "        \n",
    "        job_data = []\n",
    "        for job in jobs:\n",
    "            job_title = job.find(\"h3\", class_=\"job_title\").text.strip()\n",
    "            company_name = job.find(\"span\", class_=\"company_name\").text.strip()\n",
    "            job_location = job.find(\"span\", class_=\"loc\").text.strip()\n",
    "            \n",
    "            job_data.append({\n",
    "                \"Job Title\": job_title,\n",
    "                \"Company Name\": company_name,\n",
    "                \"Job Location\": job_location\n",
    "            })\n",
    "            \n",
    "        return pd.DataFrame(job_data)\n",
    "    else:\n",
    "        print(\"Failed to obtain data. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "\n",
    "job_title = \"data-scientist\"\n",
    "location = \"bangalore\"\n",
    "df = scrape_shine_jobs(job_title, location)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a83b40b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_element_by_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.shine.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Find the job title input field and enter \"Data Scientist\"\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m job_title_input \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element_by_id(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqsb-keyskill-sugg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m job_title_input\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Scientist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Click the search button\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_element_by_id'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# launch Chrome browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.shine.com/\") #open shine.com\n",
    "\n",
    "\n",
    "job_title_input = driver.find_element_by_id(\"qsb-keyskill-sugg\") #find input field as jon title\n",
    "job_title_input.send_keys(\"Data Scientist\")\n",
    "\n",
    "\n",
    "search_button = driver.find_element_by_class_name(\"btn-search\") #click on search\n",
    "search_button.click()\n",
    "\n",
    "# page loading\n",
    "time.sleep(2)\n",
    "\n",
    "# apply location filter \n",
    "location_filter = driver.find_element_by_xpath(\"//span[contains(text(), 'Delhi/NCR')]\")\n",
    "location_filter.click()\n",
    "\n",
    "\n",
    "salary_filter = driver.find_element_by_xpath(\"//span[contains(text(), '3-6 lakhs')]\") # apply salary ffilter b/w 3-6 lakh\n",
    "salary_filter.click()\n",
    "\n",
    "time.sleep(2) #updating results\n",
    "\n",
    "\n",
    "jobs = driver.find_elements_by_xpath(\"//li[@class='s-l-i']\")[:10] #scrape the data\n",
    "\n",
    "job_data = []\n",
    "for job in jobs:\n",
    "    job_title = job.find_element_by_class_name(\"job_title\").text.strip()\n",
    "    company_name = job.find_element_by_class_name(\"company_name\").text.strip()\n",
    "    job_location = job.find_element_by_class_name(\"loc\").text.strip()\n",
    "    experience_required = job.find_element_by_class_name(\"exp\").text.strip()\n",
    "    \n",
    "    job_data.append({\n",
    "        \"Job Title\": job_title,\n",
    "        \"Company Name\": company_name,\n",
    "        \"Job Location\": job_location,\n",
    "        \"Experience Required\": experience_required\n",
    "    })\n",
    "\n",
    "#browser close\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "df = pd.DataFrame(job_data)\n",
    "\n",
    "# display dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42c97007",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_element_by_xpath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Search for sunglasses\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m search_box \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element_by_xpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//input[@title=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSearch for products, brands and more\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m search_box\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msunglasses\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m search_box\u001b[38;5;241m.\u001b[39msubmit()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_element_by_xpath'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome() #open chrome browser\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\") #open flipkart\n",
    "\n",
    "\n",
    "try:\n",
    "    driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# search sunglasses\n",
    "search_box = driver.find_element_by_xpath(\"//input[@title='Search for products, brands and more']\")\n",
    "search_box.send_keys(\"sunglasses\")\n",
    "search_box.submit()\n",
    "\n",
    "# scrape data\n",
    "sunglasses_data = []\n",
    "while len(sunglasses_data) < 100:\n",
    "    listings = driver.find_elements_by_xpath(\"//div[@class='_1AtVbE']\")\n",
    "    for listing in listings:\n",
    "        brand = listing.find_element_by_xpath(\".//div[@class='_2WkVRV']\").text\n",
    "        description = listing.find_element_by_xpath(\".//a[@class='IRpwTa']\").text\n",
    "        price = listing.find_element_by_xpath(\".//div[@class='_30jeq3']\").text\n",
    "\n",
    "        sunglasses_data.append({\n",
    "            \"Brand\": brand,\n",
    "            \"Product Description\": description,\n",
    "            \"Price\": price\n",
    "        })\n",
    "\n",
    "   \n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") #scroll to load more\n",
    "   \n",
    "    driver.implicitly_wait(2) #wait to load more\n",
    "\n",
    "\n",
    "driver.quit() #close browser\n",
    "\n",
    "#create dataframe\n",
    "df = pd.DataFrame(sunglasses_data)\n",
    "\n",
    "# display\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7312ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=121.0.6167.139)\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001050867dc chromedriver + 4040668\n",
      "1   chromedriver                        0x000000010507e9e0 chromedriver + 4008416\n",
      "2   chromedriver                        0x0000000104cf1870 chromedriver + 284784\n",
      "3   chromedriver                        0x0000000104ccc064 chromedriver + 131172\n",
      "4   chromedriver                        0x0000000104d5b2b0 chromedriver + 717488\n",
      "5   chromedriver                        0x0000000104d6e75c chromedriver + 796508\n",
      "6   chromedriver                        0x0000000104d2974c chromedriver + 513868\n",
      "7   chromedriver                        0x0000000104d2a044 chromedriver + 516164\n",
      "8   chromedriver                        0x000000010504ba04 chromedriver + 3799556\n",
      "9   chromedriver                        0x000000010504fee4 chromedriver + 3817188\n",
      "10  chromedriver                        0x0000000105034260 chromedriver + 3703392\n",
      "11  chromedriver                        0x0000000105050a2c chromedriver + 3820076\n",
      "12  chromedriver                        0x000000010502701c chromedriver + 3649564\n",
      "13  chromedriver                        0x000000010506de3c chromedriver + 3939900\n",
      "14  chromedriver                        0x000000010506dfb4 chromedriver + 3940276\n",
      "15  chromedriver                        0x000000010507e660 chromedriver + 4007520\n",
      "16  libsystem_pthread.dylib             0x000000018914a034 _pthread_start + 136\n",
      "17  libsystem_pthread.dylib             0x0000000189144e3c thread_start + 8\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome() #launch chrome browser\n",
    "\n",
    "#open flipkart review page for iphone11\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\"\n",
    "driver.get(url)\n",
    "\n",
    "#scrape data\n",
    "reviews_data = []\n",
    "while len(reviews_data) < 100:\n",
    "    try:\n",
    "        # wait for reviews to load\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"_1AtVbE\")))\n",
    "\n",
    "        # get reviews \n",
    "        review_blocks = driver.find_elements_by_xpath(\"//div[@class='_1AtVbE']\")\n",
    "\n",
    "        #extract requirement for each review\n",
    "        for review_block in review_blocks:\n",
    "            rating = review_block.find_element_by_xpath(\".//div[@class='_3LWZlK']\").text.strip()\n",
    "            review_summary = review_block.find_element_by_xpath(\".//p[@class='_2-N8zT']\").text.strip()\n",
    "            full_review = review_block.find_element_by_xpath(\".//div[@class='t-ZTKy']\").text.strip()\n",
    "\n",
    "            reviews_data.append({\n",
    "                \"Rating\": rating,\n",
    "                \"Review Summary\": review_summary,\n",
    "                \"Full Review\": full_review\n",
    "            })\n",
    "\n",
    "            if len(reviews_data) == 100:\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        break\n",
    "\n",
    "    #click next button\n",
    "    try:\n",
    "        next_button = driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        next_button.click()\n",
    "    except:\n",
    "        break\n",
    "\n",
    "\n",
    "driver.quit() #close browser\n",
    "\n",
    "\n",
    "df = pd.DataFrame(reviews_data) #create dataframe\n",
    "\n",
    "\n",
    "print(df) #display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e55fb58d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_element_by_xpath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Search for sneakers\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m search_box \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element_by_xpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//input[@title=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSearch for products, brands and more\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m search_box\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msneakers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m search_box\u001b[38;5;241m.\u001b[39msubmit()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_element_by_xpath'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "# launch browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open website\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "try:\n",
    "    driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#search sneakers\n",
    "search_box = driver.find_element_by_xpath(\"//input[@title='Search for products, brands and more']\")\n",
    "search_box.send_keys(\"sneakers\")\n",
    "search_box.submit()\n",
    "\n",
    "# wait for result to load\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"_1AtVbE\")))\n",
    "\n",
    "#scrape data\n",
    "sneakers_data = []\n",
    "while len(sneakers_data) < 100:\n",
    "    try:\n",
    "        # get sneaker block\n",
    "        sneaker_blocks = driver.find_elements_by_xpath(\"//div[@class='_1AtVbE']\")\n",
    "\n",
    "        # extract requirement for each review\n",
    "        for sneaker_block in sneaker_blocks:\n",
    "            brand = sneaker_block.find_element_by_xpath(\".//div[@class='_2WkVRV']\").text\n",
    "            product_description = sneaker_block.find_element_by_xpath(\".//a[@class='IRpwTa']\").text\n",
    "            price = sneaker_block.find_element_by_xpath(\".//div[@class='_30jeq3']\").text\n",
    "\n",
    "            sneakers_data.append({\n",
    "                \"Brand\": brand,\n",
    "                \"Product Description\": product_description,\n",
    "                \"Price\": price\n",
    "            })\n",
    "\n",
    "            if len(sneakers_data) == 100:\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        break\n",
    "\n",
    "    # click next button to load more sneakers\n",
    "    try:\n",
    "        next_button = driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        next_button.click()\n",
    "    except:\n",
    "        break\n",
    "\n",
    "driver.quit() #close browser\n",
    "\n",
    "#create dataframe\n",
    "df = pd.DataFrame(sneakers_data)\n",
    "\n",
    "# display\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc813708",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_element_by_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.amazon.in/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# find search field and look for laptop\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m search_field \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element_by_id(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwotabsearchtextbox\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m search_field\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLaptop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#click on search icon\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_element_by_id'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "#launch chrome\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#open amazon.in\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "\n",
    "# find search field and look for laptop\n",
    "search_field = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search_field.send_keys(\"Laptop\")\n",
    "\n",
    "#click on search icon\n",
    "search_button = driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "search_button.click()\n",
    "\n",
    "#wait search result to load\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"s-result-list\")))\n",
    "\n",
    "#set cpu type filter to intel core i7\n",
    "cpu_filter = driver.find_element_by_xpath(\"//span[contains(text(), 'Intel Core i7')]\")\n",
    "cpu_filter.click()\n",
    "\n",
    "#wait for the filter for applied\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"s-result-list\")))\n",
    "\n",
    "#scrape data\n",
    "laptop_data = []\n",
    "laptop_elements = driver.find_elements_by_xpath(\"//div[@data-component-type='s-search-result']\")\n",
    "for laptop_element in laptop_elements[:10]:\n",
    "    title = laptop_element.find_element_by_xpath(\".//span[@class='a-size-medium a-color-base a-text-normal']\").text\n",
    "    ratings_element = laptop_element.find_element_by_xpath(\".//span[@class='a-icon-alt']\")\n",
    "    ratings = ratings_element.get_attribute(\"innerHTML\")\n",
    "    price_element = laptop_element.find_element_by_xpath(\".//span[@class='a-price-whole']\")\n",
    "    price = price_element.text\n",
    "    \n",
    "    laptop_data.append({\n",
    "        \"Title\": title,\n",
    "        \"Ratings\": ratings,\n",
    "        \"Price\": price\n",
    "    })\n",
    "\n",
    "#close browser\n",
    "driver.quit()\n",
    "\n",
    "#create dataframe\n",
    "df = pd.DataFrame(laptop_data)\n",
    "\n",
    "# display\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d78c91d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n0   chromedriver                        0x0000000102b1a7dc chromedriver + 4040668\n1   chromedriver                        0x0000000102b129e0 chromedriver + 4008416\n2   chromedriver                        0x0000000102785870 chromedriver + 284784\n3   chromedriver                        0x00000001027c9080 chromedriver + 561280\n4   chromedriver                        0x0000000102803048 chromedriver + 798792\n5   chromedriver                        0x00000001027bd74c chromedriver + 513868\n6   chromedriver                        0x00000001027be044 chromedriver + 516164\n7   chromedriver                        0x0000000102adfa04 chromedriver + 3799556\n8   chromedriver                        0x0000000102ae3ee4 chromedriver + 3817188\n9   chromedriver                        0x0000000102ac8260 chromedriver + 3703392\n10  chromedriver                        0x0000000102ae4a2c chromedriver + 3820076\n11  chromedriver                        0x0000000102abb01c chromedriver + 3649564\n12  chromedriver                        0x0000000102b01e3c chromedriver + 3939900\n13  chromedriver                        0x0000000102b01fb4 chromedriver + 3940276\n14  chromedriver                        0x0000000102b12660 chromedriver + 4007520\n15  libsystem_pthread.dylib             0x000000018914a034 _pthread_start + 136\n16  libsystem_pthread.dylib             0x0000000189144e3c thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.azquotes.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Click on the \"Top Quotes\" link\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m top_quotes_link \u001b[38;5;241m=\u001b[39m WebDriverWait(driver, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(EC\u001b[38;5;241m.\u001b[39melement_to_be_clickable((By\u001b[38;5;241m.\u001b[39mLINK_TEXT, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop Quotes\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m     15\u001b[0m top_quotes_link\u001b[38;5;241m.\u001b[39mclick()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Scraping the data for the top 1000 quotes\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/selenium/webdriver/support/wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nStacktrace:\n0   chromedriver                        0x0000000102b1a7dc chromedriver + 4040668\n1   chromedriver                        0x0000000102b129e0 chromedriver + 4008416\n2   chromedriver                        0x0000000102785870 chromedriver + 284784\n3   chromedriver                        0x00000001027c9080 chromedriver + 561280\n4   chromedriver                        0x0000000102803048 chromedriver + 798792\n5   chromedriver                        0x00000001027bd74c chromedriver + 513868\n6   chromedriver                        0x00000001027be044 chromedriver + 516164\n7   chromedriver                        0x0000000102adfa04 chromedriver + 3799556\n8   chromedriver                        0x0000000102ae3ee4 chromedriver + 3817188\n9   chromedriver                        0x0000000102ac8260 chromedriver + 3703392\n10  chromedriver                        0x0000000102ae4a2c chromedriver + 3820076\n11  chromedriver                        0x0000000102abb01c chromedriver + 3649564\n12  chromedriver                        0x0000000102b01e3c chromedriver + 3939900\n13  chromedriver                        0x0000000102b01fb4 chromedriver + 3940276\n14  chromedriver                        0x0000000102b12660 chromedriver + 4007520\n15  libsystem_pthread.dylib             0x000000018914a034 _pthread_start + 136\n16  libsystem_pthread.dylib             0x0000000189144e3c thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "# Launch the Chrome browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the AzQuotes website\n",
    "driver.get(\"https://www.azquotes.com/\")\n",
    "\n",
    "# Click on the \"Top Quotes\" link\n",
    "top_quotes_link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.LINK_TEXT, \"Top Quotes\")))\n",
    "top_quotes_link.click()\n",
    "\n",
    "# Scraping the data for the top 1000 quotes\n",
    "quotes_data = []\n",
    "for i in range(10):  # Loop to scroll down the page to load more quotes\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"pagination\")))\n",
    "\n",
    "quote_elements = driver.find_elements_by_xpath(\"//div[@class='wrap-block']\")\n",
    "for quote_element in quote_elements:\n",
    "    quote = quote_element.find_element_by_class_name(\"title\").text\n",
    "    author = quote_element.find_element_by_class_name(\"author\").text\n",
    "    quote_type = quote_element.find_element_by_class_name(\"kw-box\").text\n",
    "    \n",
    "    quotes_data.append({\n",
    "        \"Quote\": quote,\n",
    "        \"Author\": author,\n",
    "        \"Type of Quote\": quote_type\n",
    "    })\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(quotes_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42cb5ae0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=121.0.6167.160)\nStacktrace:\n0   chromedriver                        0x0000000102bee7dc chromedriver + 4040668\n1   chromedriver                        0x0000000102be69e0 chromedriver + 4008416\n2   chromedriver                        0x0000000102859870 chromedriver + 284784\n3   chromedriver                        0x0000000102834064 chromedriver + 131172\n4   chromedriver                        0x00000001028c32b0 chromedriver + 717488\n5   chromedriver                        0x00000001028d675c chromedriver + 796508\n6   chromedriver                        0x000000010289174c chromedriver + 513868\n7   chromedriver                        0x0000000102892044 chromedriver + 516164\n8   chromedriver                        0x0000000102bb3a04 chromedriver + 3799556\n9   chromedriver                        0x0000000102bb7ee4 chromedriver + 3817188\n10  chromedriver                        0x0000000102b9c260 chromedriver + 3703392\n11  chromedriver                        0x0000000102bb8a2c chromedriver + 3820076\n12  chromedriver                        0x0000000102b8f01c chromedriver + 3649564\n13  chromedriver                        0x0000000102bd5e3c chromedriver + 3939900\n14  chromedriver                        0x0000000102bd5fb4 chromedriver + 3940276\n15  chromedriver                        0x0000000102be6660 chromedriver + 4007520\n16  libsystem_pthread.dylib             0x000000018914a034 _pthread_start + 136\n17  libsystem_pthread.dylib             0x0000000189144e3c thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m gk_option\u001b[38;5;241m.\u001b[39mclick()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Click on the \"List of all Prime Ministers of India\" link\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m prime_ministers_link \u001b[38;5;241m=\u001b[39m WebDriverWait(driver, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(EC\u001b[38;5;241m.\u001b[39melement_to_be_clickable((By\u001b[38;5;241m.\u001b[39mLINK_TEXT, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList of all Prime Ministers of India\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m     19\u001b[0m prime_ministers_link\u001b[38;5;241m.\u001b[39mclick()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Scrape the data\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/selenium/webdriver/support/wait.py:96\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m         value \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_driver)\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value:\n\u001b[1;32m     98\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/selenium/webdriver/support/expected_conditions.py:363\u001b[0m, in \u001b[0;36melement_to_be_clickable.<locals>._predicate\u001b[0;34m(driver)\u001b[0m\n\u001b[1;32m    361\u001b[0m target \u001b[38;5;241m=\u001b[39m mark\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, WebElement):  \u001b[38;5;66;03m# if given locator instead of WebElement\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     target \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(\u001b[38;5;241m*\u001b[39mtarget)  \u001b[38;5;66;03m# grab element at locator\u001b[39;00m\n\u001b[1;32m    364\u001b[0m element \u001b[38;5;241m=\u001b[39m visibility_of(target)(driver)\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m element \u001b[38;5;129;01mand\u001b[39;00m element\u001b[38;5;241m.\u001b[39mis_enabled():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    738\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[1;32m    739\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[1;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=121.0.6167.160)\nStacktrace:\n0   chromedriver                        0x0000000102bee7dc chromedriver + 4040668\n1   chromedriver                        0x0000000102be69e0 chromedriver + 4008416\n2   chromedriver                        0x0000000102859870 chromedriver + 284784\n3   chromedriver                        0x0000000102834064 chromedriver + 131172\n4   chromedriver                        0x00000001028c32b0 chromedriver + 717488\n5   chromedriver                        0x00000001028d675c chromedriver + 796508\n6   chromedriver                        0x000000010289174c chromedriver + 513868\n7   chromedriver                        0x0000000102892044 chromedriver + 516164\n8   chromedriver                        0x0000000102bb3a04 chromedriver + 3799556\n9   chromedriver                        0x0000000102bb7ee4 chromedriver + 3817188\n10  chromedriver                        0x0000000102b9c260 chromedriver + 3703392\n11  chromedriver                        0x0000000102bb8a2c chromedriver + 3820076\n12  chromedriver                        0x0000000102b8f01c chromedriver + 3649564\n13  chromedriver                        0x0000000102bd5e3c chromedriver + 3939900\n14  chromedriver                        0x0000000102bd5fb4 chromedriver + 3940276\n15  chromedriver                        0x0000000102be6660 chromedriver + 4007520\n16  libsystem_pthread.dylib             0x000000018914a034 _pthread_start + 136\n17  libsystem_pthread.dylib             0x0000000189144e3c thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "# Launch the Chrome browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the Jagran Josh website\n",
    "driver.get(\"https://www.jagranjosh.com/\")\n",
    "\n",
    "# Click on the \"GK\" option\n",
    "gk_option = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.LINK_TEXT, \"GK\")))\n",
    "gk_option.click()\n",
    "\n",
    "# Click on the \"List of all Prime Ministers of India\" link\n",
    "prime_ministers_link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.LINK_TEXT, \"List of all Prime Ministers of India\")))\n",
    "prime_ministers_link.click()\n",
    "\n",
    "# Scrape the data\n",
    "prime_ministers_data = []\n",
    "rows = driver.find_elements_by_xpath(\"//table[@class='specTable']/tbody/tr\")\n",
    "for row in rows:\n",
    "    cells = row.find_elements_by_xpath(\".//td\")\n",
    "    if len(cells) == 4:  # Ensure the row has all required data\n",
    "        name = cells[0].text\n",
    "        born_dead = cells[1].text\n",
    "        term_of_office = cells[2].text\n",
    "        remarks = cells[3].text\n",
    "        \n",
    "        prime_ministers_data.append({\n",
    "            \"Name\": name,\n",
    "            \"Born-Dead\": born_dead,\n",
    "            \"Term of Office\": term_of_office,\n",
    "            \"Remarks\": remarks\n",
    "        })\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(prime_ministers_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcafd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "# #launch chrome browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# #open motor1 website\n",
    "driver.get(\"https://www.motor1.com/\")\n",
    "\n",
    "# search 50 most expensive cars\n",
    "search_bar = driver.find_element_by_id(\"search-input\")\n",
    "search_bar.send_keys(\"50 most expensive cars\")\n",
    "search_bar.send_keys(Keys.RETURN)\n",
    "\n",
    "#click on 50 most expensive cars in the world, link\n",
    "try:\n",
    "    link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.LINK_TEXT, \"50 most expensive cars in the world\")))\n",
    "    link.click()\n",
    "except:\n",
    "    print(\"Link not found\")\n",
    "    driver.quit()\n",
    "\n",
    "# scrape data\n",
    "cars_data = []\n",
    "car_elements = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH, \"//div[@class='slide-content']\")))\n",
    "for car_element in car_elements[:50]:  # Only scrape data for the first 50 cars\n",
    "    car_name = car_element.find_element_by_class_name(\"slide-title\").text\n",
    "    car_price = car_element.find_element_by_class_name(\"price\").text\n",
    "    \n",
    "    cars_data.append({\n",
    "        \"Car Name\": car_name,\n",
    "        \"Price\": car_price\n",
    "    })\n",
    "\n",
    "#close browser\n",
    "driver.quit()\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame(cars_data)\n",
    "\n",
    "# display \n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
